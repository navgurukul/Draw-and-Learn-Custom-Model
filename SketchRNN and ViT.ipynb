{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZ74ktyO7Myv",
    "outputId": "60c66358-2d9c-45ad-e9fc-cd8e446836a8"
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 1Ô∏è‚É£ Imports\n",
    "# =====================================================\n",
    "import os\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# =====================================================\n",
    "# 2Ô∏è‚É£ Configurations\n",
    "# =====================================================\n",
    "DATA_DIR = \"quickdraw_npy\"\n",
    "SAMPLES_PER_CLASS = 2000\n",
    "IMG_SIZE = 28\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "PATIENCE = 7\n",
    "TARGET_LOSS = 0.01\n",
    "\n",
    "# ‚úÖ Categories (51)\n",
    "categories = [\n",
    "    \"airplane\",\"ant\",\"apple\",\"backpack\",\"banana\",\"bed\",\"bicycle\",\"bird\",\"book\",\"bread\",\n",
    "    \"bus\",\"cake\",\"camera\",\"car\",\"cat\",\"chair\",\"clock\",\"computer\",\"cup\",\"dog\",\"door\",\n",
    "    \"duck\",\"envelope\",\"eye\",\"face\",\"fish\",\"flower\",\"fork\",\"frog\",\"guitar\",\"hat\",\"horse\",\n",
    "    \"house\",\"lollipop\",\"pencil\",\"pig\",\"pizza\",\"rabbit\",\"shoe\",\"snake\",\"spider\",\"spoon\",\n",
    "    \"star\",\"sun\",\"train\",\"tree\",\"truck\",\"umbrella\",\"alarm_clock\",\"birthday_cake\",\"butterfly\"\n",
    "]\n",
    "print(\"üì¶ Total categories:\", len(categories))\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# =====================================================\n",
    "# 3Ô∏è‚É£ Download .npy Files with Error Handling\n",
    "# =====================================================\n",
    "def download_drawings():\n",
    "    base_url = \"https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap\"\n",
    "    failed = []\n",
    "    for cat in tqdm(categories, desc=\"‚è¨ Downloading categories\"):\n",
    "        file_path = os.path.join(DATA_DIR, f\"{cat}.npy\")\n",
    "        if not os.path.exists(file_path):\n",
    "            url = f\"{base_url}/{cat.replace('_', '%20')}.npy\"  # Handle underscores\n",
    "            try:\n",
    "                urllib.request.urlretrieve(url, file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to download {cat}: {e}\")\n",
    "                failed.append(cat)\n",
    "    print(\"‚úÖ Download complete!\")\n",
    "    if failed:\n",
    "        print(f\"‚ö†Ô∏è Failed downloads: {failed}\")\n",
    "\n",
    "download_drawings()\n",
    "\n",
    "# =====================================================\n",
    "# 4Ô∏è‚É£ Dataset Class\n",
    "# =====================================================\n",
    "class SketchRNNDataset(Dataset):\n",
    "    def __init__(self, root_dir, categories, samples_per_class):\n",
    "        self.data, self.labels = [], []\n",
    "        for label, cat in enumerate(categories):\n",
    "            file_path = os.path.join(root_dir, f\"{cat}.npy\")\n",
    "            if not os.path.exists(file_path):\n",
    "                continue  # Skip missing files\n",
    "            drawings = np.load(file_path)\n",
    "            drawings = drawings.reshape(-1, IMG_SIZE, IMG_SIZE)\n",
    "            if len(drawings) < samples_per_class:\n",
    "                continue\n",
    "            idx = np.random.choice(len(drawings), samples_per_class, replace=False)\n",
    "            self.data.append(drawings[idx])\n",
    "            self.labels.extend([label] * samples_per_class)\n",
    "        self.data = np.vstack(self.data).astype(np.float32) / 255.0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.data[idx]).unsqueeze(0)  # (1, 28, 28)\n",
    "        y = self.labels[idx]\n",
    "        return x, y\n",
    "\n",
    "# =====================================================\n",
    "# 5Ô∏è‚É£ Prepare Dataset\n",
    "# =====================================================\n",
    "dataset = SketchRNNDataset(DATA_DIR, categories, SAMPLES_PER_CLASS)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size   = int(0.1 * len(dataset))\n",
    "test_size  = len(dataset) - train_size - val_size\n",
    "\n",
    "train_data, val_data, test_data = random_split(dataset, [train_size, val_size, test_size])\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_data, batch_size=BATCH_SIZE)\n",
    "test_loader  = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"‚úÖ Dataset ready! Train: {len(train_data)} | Val: {len(val_data)} | Test: {len(test_data)}\")\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 7Ô∏è‚É£ Train Setup\n",
    "# =====================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SketchRNN().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# =====================================================\n",
    "# 8Ô∏è‚É£ Training Loop with Early Stopping\n",
    "# =====================================================\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for x, _ in train_loader:\n",
    "        x = x.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon = model(x)\n",
    "        loss = criterion(recon, x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "    avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, _ in val_loader:\n",
    "            x = x.to(device)\n",
    "            recon = model(x)\n",
    "            loss = criterion(recon, x)\n",
    "            val_loss += loss.item() * x.size(0)\n",
    "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"üìä Epoch {epoch+1}/{EPOCHS} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), \"best_sketch_rnn.pth\")\n",
    "        print(\"üíæ Saved new best model.\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(\"‚èπÔ∏è Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    if avg_val_loss <= TARGET_LOSS:\n",
    "        print(f\"üèÅ Target loss {TARGET_LOSS} reached.\")\n",
    "        break\n",
    "\n",
    "print(\"‚úÖ Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SketchRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "L7VhrZBo-d1Y"
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 6Ô∏è‚É£ SketchRNN Classifier (instead of Autoencoder)\n",
    "# =====================================================\n",
    "class SketchRNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=len(categories)):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, stride=2, padding=1),  # -> 14x14\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),  # -> 7x7\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc = nn.Linear(256, num_classes)  # classification head\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UqqCOr6D-hbj"
   },
   "outputs": [],
   "source": [
    "model = SketchRNNClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OqB3Klye_HE4",
    "outputId": "17e3345a-113f-4b84-c80c-4f34de5ca548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 1/50 | Train Loss: 1.6073, Acc: 0.5721 | Val Loss: 1.1494, Acc: 0.6839\n",
      "üìä Epoch 2/50 | Train Loss: 1.0162, Acc: 0.7214 | Val Loss: 0.9856, Acc: 0.7334\n",
      "üìä Epoch 3/50 | Train Loss: 0.8391, Acc: 0.7646 | Val Loss: 0.9425, Acc: 0.7379\n",
      "üìä Epoch 4/50 | Train Loss: 0.7134, Acc: 0.7963 | Val Loss: 0.9278, Acc: 0.7452\n",
      "üìä Epoch 5/50 | Train Loss: 0.6088, Acc: 0.8220 | Val Loss: 0.9571, Acc: 0.7463\n",
      "üìä Epoch 6/50 | Train Loss: 0.5088, Acc: 0.8501 | Val Loss: 0.9873, Acc: 0.7455\n",
      "üìä Epoch 7/50 | Train Loss: 0.4211, Acc: 0.8714 | Val Loss: 1.0758, Acc: 0.7407\n",
      "üìä Epoch 8/50 | Train Loss: 0.3400, Acc: 0.8952 | Val Loss: 1.1704, Acc: 0.7325\n",
      "üìä Epoch 9/50 | Train Loss: 0.2750, Acc: 0.9123 | Val Loss: 1.3017, Acc: 0.7306\n",
      "üìä Epoch 10/50 | Train Loss: 0.2225, Acc: 0.9278 | Val Loss: 1.4354, Acc: 0.7285\n",
      "üìä Epoch 11/50 | Train Loss: 0.1822, Acc: 0.9410 | Val Loss: 1.5613, Acc: 0.7200\n",
      "üìä Epoch 12/50 | Train Loss: 0.1493, Acc: 0.9511 | Val Loss: 1.7462, Acc: 0.7217\n",
      "üìä Epoch 13/50 | Train Loss: 0.1292, Acc: 0.9575 | Val Loss: 1.8552, Acc: 0.7248\n",
      "üìä Epoch 14/50 | Train Loss: 0.1150, Acc: 0.9617 | Val Loss: 1.9863, Acc: 0.7230\n",
      "üìä Epoch 15/50 | Train Loss: 0.1029, Acc: 0.9649 | Val Loss: 2.1465, Acc: 0.7211\n",
      "üìä Epoch 16/50 | Train Loss: 0.0913, Acc: 0.9698 | Val Loss: 2.1476, Acc: 0.7224\n",
      "üìä Epoch 17/50 | Train Loss: 0.0806, Acc: 0.9725 | Val Loss: 2.3252, Acc: 0.7166\n",
      "üìä Epoch 18/50 | Train Loss: 0.0787, Acc: 0.9729 | Val Loss: 2.3323, Acc: 0.7185\n",
      "üìä Epoch 19/50 | Train Loss: 0.0698, Acc: 0.9767 | Val Loss: 2.4660, Acc: 0.7204\n",
      "üìä Epoch 20/50 | Train Loss: 0.0668, Acc: 0.9782 | Val Loss: 2.5596, Acc: 0.7202\n",
      "üìä Epoch 21/50 | Train Loss: 0.0619, Acc: 0.9793 | Val Loss: 2.6253, Acc: 0.7176\n",
      "üìä Epoch 22/50 | Train Loss: 0.0637, Acc: 0.9779 | Val Loss: 2.7342, Acc: 0.7201\n",
      "üìä Epoch 23/50 | Train Loss: 0.0600, Acc: 0.9800 | Val Loss: 2.7302, Acc: 0.7173\n",
      "üìä Epoch 24/50 | Train Loss: 0.0547, Acc: 0.9812 | Val Loss: 2.7913, Acc: 0.7199\n",
      "üìä Epoch 25/50 | Train Loss: 0.0555, Acc: 0.9818 | Val Loss: 2.8899, Acc: 0.7145\n",
      "üìä Epoch 26/50 | Train Loss: 0.0477, Acc: 0.9841 | Val Loss: 2.9088, Acc: 0.7134\n",
      "üìä Epoch 27/50 | Train Loss: 0.0536, Acc: 0.9824 | Val Loss: 3.0094, Acc: 0.7203\n",
      "üìä Epoch 28/50 | Train Loss: 0.0477, Acc: 0.9841 | Val Loss: 3.0452, Acc: 0.7178\n",
      "üìä Epoch 29/50 | Train Loss: 0.0458, Acc: 0.9851 | Val Loss: 3.0089, Acc: 0.7139\n",
      "üìä Epoch 30/50 | Train Loss: 0.0465, Acc: 0.9846 | Val Loss: 3.1271, Acc: 0.7173\n",
      "üìä Epoch 31/50 | Train Loss: 0.0447, Acc: 0.9853 | Val Loss: 3.2287, Acc: 0.7187\n",
      "üìä Epoch 32/50 | Train Loss: 0.0380, Acc: 0.9871 | Val Loss: 3.2367, Acc: 0.7135\n",
      "üìä Epoch 33/50 | Train Loss: 0.0413, Acc: 0.9865 | Val Loss: 3.2140, Acc: 0.7180\n",
      "üìä Epoch 34/50 | Train Loss: 0.0453, Acc: 0.9848 | Val Loss: 3.2639, Acc: 0.7214\n",
      "üìä Epoch 35/50 | Train Loss: 0.0391, Acc: 0.9872 | Val Loss: 3.3023, Acc: 0.7187\n",
      "üìä Epoch 36/50 | Train Loss: 0.0375, Acc: 0.9874 | Val Loss: 3.5132, Acc: 0.7147\n",
      "üìä Epoch 37/50 | Train Loss: 0.0374, Acc: 0.9877 | Val Loss: 3.4776, Acc: 0.7203\n",
      "üìä Epoch 38/50 | Train Loss: 0.0362, Acc: 0.9885 | Val Loss: 3.4450, Acc: 0.7186\n",
      "üìä Epoch 39/50 | Train Loss: 0.0375, Acc: 0.9875 | Val Loss: 3.5014, Acc: 0.7152\n",
      "üìä Epoch 40/50 | Train Loss: 0.0369, Acc: 0.9882 | Val Loss: 3.6694, Acc: 0.7157\n",
      "üìä Epoch 41/50 | Train Loss: 0.0377, Acc: 0.9882 | Val Loss: 3.6202, Acc: 0.7170\n",
      "üìä Epoch 42/50 | Train Loss: 0.0325, Acc: 0.9898 | Val Loss: 3.6030, Acc: 0.7198\n",
      "üìä Epoch 43/50 | Train Loss: 0.0336, Acc: 0.9893 | Val Loss: 3.7196, Acc: 0.7149\n",
      "üìä Epoch 44/50 | Train Loss: 0.0349, Acc: 0.9892 | Val Loss: 3.6836, Acc: 0.7200\n",
      "üìä Epoch 45/50 | Train Loss: 0.0311, Acc: 0.9898 | Val Loss: 3.7201, Acc: 0.7150\n",
      "üìä Epoch 46/50 | Train Loss: 0.0331, Acc: 0.9892 | Val Loss: 3.7728, Acc: 0.7185\n",
      "üìä Epoch 47/50 | Train Loss: 0.0295, Acc: 0.9899 | Val Loss: 3.6466, Acc: 0.7146\n",
      "üìä Epoch 48/50 | Train Loss: 0.0297, Acc: 0.9907 | Val Loss: 3.8137, Acc: 0.7119\n",
      "üìä Epoch 49/50 | Train Loss: 0.0336, Acc: 0.9894 | Val Loss: 3.8590, Acc: 0.7193\n",
      "üìä Epoch 50/50 | Train Loss: 0.0285, Acc: 0.9909 | Val Loss: 3.8548, Acc: 0.7175\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    # ---- Train ----\n",
    "    model.train()\n",
    "    train_loss, correct, total = 0, 0, 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # ---- Validation ----\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            val_loss += loss.item() * x.size(0)\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "    val_acc = correct / total\n",
    "\n",
    "    print(f\"üìä Epoch {epoch+1}/{EPOCHS} | \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RcVWyiUG_PLI",
    "outputId": "a136cd68-7aa6-45f1-8359-8a39ad3930e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Test Accuracy: 0.7192\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 9Ô∏è‚É£ Evaluate on Test Set\n",
    "# =====================================================\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        outputs = model(x)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "test_acc = correct / total\n",
    "print(f\"‚úÖ Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "4zA89K9oAq-J",
    "outputId": "0e3ea50e-c066-4ac2-c791-05ba92ac308b"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'quickdraw_npy/airplane.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-876179889.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m ])\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSketchDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAMPLES_PER_CLASS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mval_size\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-876179889.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root_dir, categories, samples_per_class, transform)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{cat}.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mdrawings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mdrawings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrawings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrawings\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msamples_per_class\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'quickdraw_npy/airplane.npy'"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 1Ô∏è‚É£ Imports\n",
    "# =====================================================\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# =====================================================\n",
    "# 2Ô∏è‚É£ Configurations\n",
    "# =====================================================\n",
    "DATA_DIR = \"quickdraw_npy\"\n",
    "SAMPLES_PER_CLASS = 8000   # ViT expects 224x224\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "LR = 1e-4\n",
    "NUM_CLASSES = 51\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "categories = [\n",
    "    \"airplane\",\"ant\",\"apple\",\"backpack\",\"banana\",\"bed\",\"bicycle\",\"bird\",\"book\",\"bread\",\n",
    "    \"bus\",\"cake\",\"camera\",\"car\",\"cat\",\"chair\",\"clock\",\"computer\",\"cup\",\"dog\",\"door\",\n",
    "    \"duck\",\"envelope\",\"eye\",\"face\",\"fish\",\"flower\",\"fork\",\"frog\",\"guitar\",\"hat\",\"horse\",\n",
    "    \"house\",\"lollipop\",\"pencil\",\"pig\",\"pizza\",\"rabbit\",\"shoe\",\"snake\",\"spider\",\"spoon\",\n",
    "    \"star\",\"sun\",\"train\",\"tree\",\"truck\",\"umbrella\",\"alarm_clock\",\"birthday_cake\",\"butterfly\"\n",
    "]\n",
    "\n",
    "# =====================================================\n",
    "# 3Ô∏è‚É£ Dataset\n",
    "# =====================================================\n",
    "class SketchDataset(Dataset):\n",
    "    def __init__(self, root_dir, categories, samples_per_class, transform=None):\n",
    "        self.data, self.labels = [], []\n",
    "        self.transform = transform\n",
    "        for label, cat in enumerate(categories):\n",
    "            file_path = os.path.join(root_dir, f\"{cat}.npy\")\n",
    "            drawings = np.load(file_path)\n",
    "            drawings = drawings.reshape(-1, 28, 28)\n",
    "            if len(drawings) < samples_per_class:\n",
    "                continue\n",
    "            idx = np.random.choice(len(drawings), samples_per_class, replace=False)\n",
    "            self.data.append(drawings[idx])\n",
    "            self.labels.extend([label] * samples_per_class)\n",
    "\n",
    "        self.data = np.vstack(self.data).astype(np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data[idx]\n",
    "        img = np.stack([img]*3, axis=-1)  # convert grayscale -> 3 channels\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        y = self.labels[idx]\n",
    "        return img, y\n",
    "\n",
    "# =====================================================\n",
    "# 4Ô∏è‚É£ Data transforms (resize + normalization for ViT)\n",
    "# =====================================================\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
    "])\n",
    "\n",
    "dataset = SketchDataset(DATA_DIR, categories, SAMPLES_PER_CLASS, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size   = int(0.1 * len(dataset))\n",
    "test_size  = len(dataset) - train_size - val_size\n",
    "train_data, val_data, test_data = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader   = DataLoader(val_data, batch_size=BATCH_SIZE, num_workers=2)\n",
    "test_loader  = DataLoader(test_data, batch_size=BATCH_SIZE, num_workers=2)\n",
    "\n",
    "print(f\"‚úÖ Dataset ready! Train: {len(train_data)} | Val: {len(val_data)} | Test: {len(test_data)}\")\n",
    "\n",
    "# =====================================================\n",
    "# 5Ô∏è‚É£ Vision Transformer Model\n",
    "# =====================================================\n",
    "model = models.vit_b_16(weights=\"IMAGENET1K_V1\")   # Pretrained\n",
    "model.heads.head = nn.Linear(model.heads.head.in_features, NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "# =====================================================\n",
    "# 6Ô∏è‚É£ Training Loop\n",
    "# =====================================================\n",
    "def train_model(model, train_loader, val_loader, epochs):\n",
    "    best_val_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        # ---- Train ----\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0, 0, 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * x.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "        train_acc = correct / total\n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "        # ---- Validation ----\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "                outputs = model(x)\n",
    "                loss = criterion(outputs, y)\n",
    "                val_loss += loss.item() * x.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += (predicted == y).sum().item()\n",
    "                total += y.size(0)\n",
    "\n",
    "        val_acc = correct / total\n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "\n",
    "        print(f\"üìä Epoch {epoch+1}/{epochs} | \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"best_vit.pth\")\n",
    "            print(\"üíæ Saved new best model.\")\n",
    "\n",
    "    print(\"‚úÖ Training complete.\")\n",
    "\n",
    "# Train\n",
    "train_model(model, train_loader, val_loader, EPOCHS)\n",
    "\n",
    "# =====================================================\n",
    "# 7Ô∏è‚É£ Evaluate on Test Set\n",
    "# =====================================================\n",
    "model.load_state_dict(torch.load(\"best_vit.pth\"))  # load best checkpoint\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        outputs = model(x)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "test_acc = correct / total\n",
    "print(f\"üéØ Test Accuracy (ViT): {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_GNhY3DDHYR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "Welcome To Colab",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

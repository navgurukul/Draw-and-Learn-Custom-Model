{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Draw-and-Learn Custom Model Training with SageMaker\n",
    "\n",
    "This notebook demonstrates how to train a custom drawing recognition model using AWS SageMaker.\n",
    "\n",
    "## Overview\n",
    "- Load and preprocess drawing data\n",
    "- Set up SageMaker training job\n",
    "- Train custom model\n",
    "- Deploy model for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import custom utilities\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from sagemaker_utils import SageMakerHelper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Initialize SageMaker Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "print(f\"SageMaker role: {role}\")\n",
    "print(f\"S3 bucket: {bucket}\")\n",
    "print(f\"AWS region: {region}\")\n",
    "\n",
    "# Initialize helper\n",
    "helper = SageMakerHelper('../config/sagemaker_config.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your data to S3 (replace with your data path)\n",
    "local_data_path = '../data/raw'\n",
    "\n",
    "if os.path.exists(local_data_path):\n",
    "    input_data_uri = helper.upload_data_to_s3(local_data_path, 'data/raw')\n",
    "    print(f\"Data uploaded to: {input_data_uri}\")\n",
    "else:\n",
    "    print(\"Please add your training data to the ../data/raw directory\")\n",
    "    input_data_uri = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Data Preprocessing with SageMaker Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up SageMaker processing job\n",
    "if input_data_uri:\n",
    "    processor = SKLearnProcessor(\n",
    "        framework_version=\"0.23-1\",\n",
    "        instance_type=\"ml.m5.large\",\n",
    "        instance_count=1,\n",
    "        role=role\n",
    "    )\n",
    "    \n",
    "    # Run preprocessing\n",
    "    processor.run(\n",
    "        code=\"../scripts/processing/preprocess.py\",\n",
    "        inputs=[\n",
    "            ProcessingInput(source=input_data_uri, destination=\"/opt/ml/processing/input\")\n",
    "        ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(output_name=\"processed_data\", source=\"/opt/ml/processing/output\")\n",
    "        ],\n",
    "        arguments=[\"--image-size\", \"224\", \"224\"]\n",
    "    )\n",
    "    \n",
    "    # Get processed data location\n",
    "    preprocessing_job_description = processor.jobs[-1].describe()\n",
    "    processed_data_uri = preprocessing_job_description['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri']\n",
    "    print(f\"Processed data available at: {processed_data_uri}\")\n",
    "else:\n",
    "    print(\"Skipping preprocessing - no input data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training job\n",
    "if 'processed_data_uri' in locals():\n",
    "    # Training hyperparameters\n",
    "    hyperparameters = {\n",
    "        'epochs': 10,\n",
    "        'batch-size': 32,\n",
    "        'learning-rate': 0.001,\n",
    "        'num-classes': 10  # Adjust based on your dataset\n",
    "    }\n",
    "    \n",
    "    # Create PyTorch estimator\n",
    "    estimator = PyTorch(\n",
    "        entry_point='train.py',\n",
    "        source_dir='../scripts/training',\n",
    "        role=role,\n",
    "        instance_type='ml.m5.xlarge',\n",
    "        instance_count=1,\n",
    "        framework_version='1.12',\n",
    "        py_version='py38',\n",
    "        hyperparameters=hyperparameters,\n",
    "        output_path=f's3://{bucket}/draw-learn-model/output/',\n",
    "        code_location=f's3://{bucket}/draw-learn-model/code/'\n",
    "    )\n",
    "    \n",
    "    # Start training\n",
    "    train_data_uri = f\"{processed_data_uri}/train\"\n",
    "    val_data_uri = f\"{processed_data_uri}/validation\"\n",
    "    \n",
    "    estimator.fit({\n",
    "        'training': train_data_uri,\n",
    "        'validation': val_data_uri\n",
    "    })\n",
    "    \n",
    "    print(\"Training completed!\")\n",
    "    print(f\"Model artifacts: {estimator.model_data}\")\n",
    "else:\n",
    "    print(\"Skipping training - no processed data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the trained model\n",
    "if 'estimator' in locals():\n",
    "    predictor = estimator.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type='ml.m5.large',\n",
    "        endpoint_name='draw-learn-endpoint'\n",
    "    )\n",
    "    \n",
    "    print(f\"Model deployed to endpoint: {predictor.endpoint_name}\")\n",
    "else:\n",
    "    print(\"Skipping deployment - no trained model available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the deployed model (example)\n",
    "if 'predictor' in locals():\n",
    "    import numpy as np\n",
    "    \n",
    "    # Create dummy test data (replace with real test image)\n",
    "    test_data = np.random.rand(1, 3, 224, 224).tolist()\n",
    "    \n",
    "    # Make prediction\n",
    "    result = predictor.predict({'instances': test_data})\n",
    "    print(f\"Prediction result: {result}\")\n",
    "else:\n",
    "    print(\"Skipping inference test - no deployed model available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up resources (uncomment when ready to delete)\n",
    "# if 'predictor' in locals():\n",
    "#     predictor.delete_endpoint()\n",
    "#     print(\"Endpoint deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Data Collection**: Add your drawing/image data to the `data/raw` directory\n",
    "2. **Model Customization**: Modify the model architecture in `src/models/custom_model.py`\n",
    "3. **Hyperparameter Tuning**: Use SageMaker Hyperparameter Tuning for optimization\n",
    "4. **Model Monitoring**: Set up CloudWatch monitoring for your deployed model\n",
    "5. **Batch Transform**: Use SageMaker Batch Transform for batch predictions\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [SageMaker Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/)\n",
    "- [SageMaker Python SDK](https://sagemaker.readthedocs.io/)\n",
    "- [PyTorch on SageMaker](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/index.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}